{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, ElasticNet, Lasso, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import make_scorer, f1_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON\n",
    "with open('algoparams_from_ui.json.rtf', 'r') as f: \n",
    "    rtfText = f.read() \n",
    "plainText = rtf_to_text(rtfText)\n",
    "mainDict = json.loads(plainText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the Dicts in mainDict\n",
    "session_info = mainDict['design_state_data']['session_info']\n",
    "target = mainDict['design_state_data']['target']\n",
    "train = mainDict['design_state_data']['train']\n",
    "metrics = mainDict['design_state_data']['metrics']\n",
    "feature_handling = mainDict['design_state_data']['feature_handling']\n",
    "feature_generation = mainDict['design_state_data']['feature_generation']\n",
    "feature_reduction = mainDict['design_state_data']['feature_reduction']\n",
    "hyperparameters = mainDict['design_state_data']['hyperparameters']\n",
    "weighting_stratergy = mainDict['design_state_data']['weighting_stratergy']\n",
    "probability_calibration = mainDict['design_state_data']['probability_calibration']\n",
    "algorithms = mainDict['design_state_data']['algorithms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying algorithms to test\n",
    "algorithms['RandomForestClassifier']['is_selected'] = True\n",
    "algorithms['GBTRegressor']['is_selected'] = True\n",
    "algorithms['GBTRegressor']['use_deviance'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target\n",
    "def getTarget(targetDict):\n",
    "    target = targetDict['target']\n",
    "    regtype = targetDict['type']\n",
    "    return target, regtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for GBT\n",
    "def lossGBT(algoDict, typ):\n",
    "    if typ == 'clf':\n",
    "        if algoDict['GBTClassifier']['use_deviance'] == True:\n",
    "            return 'deviance'\n",
    "        elif algoDict['GBTClassifier']['use_exponential'] == True:\n",
    "            return 'exponential'\n",
    "        else:\n",
    "            return 'exponential'\n",
    "    elif typ == 'reg':\n",
    "        if algoDict['GBTRegressor']['use_deviance'] == True:\n",
    "            return 'deviance'\n",
    "        elif algoDict['GBTRegressor']['use_exponential'] == True:\n",
    "            return 'exponential'\n",
    "        else:\n",
    "            return 'exponential' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for DT\n",
    "def critDT(algoDict, typ):\n",
    "    if typ == 'clf':\n",
    "        if algoDict['DecisionTreeClassifier']['use_gini'] == True:\n",
    "            return 'gini'\n",
    "        elif algoDict['DecisionTreeClassifier']['use_entropy'] == True:\n",
    "            return 'entropy'\n",
    "        else:\n",
    "            return 'gini'\n",
    "    elif typ == 'reg':\n",
    "        if algoDict['DecisionTreeRegressor']['use_gini'] == True:\n",
    "            return 'gini'\n",
    "        elif algoDict['DecisionTreeRegressor']['use_entropy'] == True:\n",
    "            return 'entropy'\n",
    "        else:\n",
    "            return 'gini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for DT\n",
    "def splitDT(algoDict, typ):\n",
    "    if typ == 'clf':\n",
    "        if algoDict['DecisionTreeClassifier']['use_best'] == True:\n",
    "            return 'best'\n",
    "        elif algoDict['DecisionTreeClassifier']['use_random'] == True:\n",
    "            return 'random'\n",
    "        else:\n",
    "            return 'best'\n",
    "    elif typ == 'reg':\n",
    "        if algoDict['DecisionTreeRegressor']['use_best'] == True:\n",
    "            return 'best'\n",
    "        elif algoDict['DecisionTreeRegressor']['use_random'] == True:\n",
    "            return 'random'\n",
    "        else:\n",
    "            return 'best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for SVM\n",
    "def kernelSVM(algoDict):\n",
    "    if algoDict['SVM']['linear_kernel'] == True:\n",
    "        return 'linear'\n",
    "    elif algoDict['SVM']['polynomial_kernel'] == True:\n",
    "        return 'poly'\n",
    "    elif algoDict['SVM']['sigmoid_kernel'] == True:\n",
    "        return 'sigmoid'\n",
    "    else:\n",
    "        return 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for SVM\n",
    "def gammaSVM(algoDict):\n",
    "    if algoDict['SVM']['auto'] == True:\n",
    "        return 'auto'\n",
    "    elif algoDict['SVM']['scale'] == True:\n",
    "        return 'scale'\n",
    "    else:\n",
    "        return 'scale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for SGD\n",
    "def lossSGD(algoDict):\n",
    "    if algoDict['SGD']['use_logistics'] == True:\n",
    "        return 'log'\n",
    "    elif algoDict['SGD']['use_modified_huber_loss'] == True:\n",
    "        return 'modified_huber'\n",
    "    else:\n",
    "        return 'hinge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for SGD\n",
    "def penaltySGD(algoDict):\n",
    "    if algoDict['SGD']['use_elastic_net_regularization'] == True:\n",
    "        return 'elasticnet'\n",
    "    elif algoDict['SGD']['use_l1_regularization'] == 'on':\n",
    "        return 'l1'\n",
    "    else:\n",
    "        return 'l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for kNN\n",
    "def weightKNN(algoDict):\n",
    "    if algoDict['KNN']['distance_weighting'] == True:\n",
    "        return 'distance'\n",
    "    else:\n",
    "        return 'uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in modelStr to return ScikitLearn object\n",
    "def transformStrToModelObj(modelStr, algoDict, regtype):\n",
    "    if modelStr == 'RandomForestClassifier':\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators = algoDict[modelStr]['max_trees'],\n",
    "            max_depth = algoDict[modelStr]['max_depth'],\n",
    "            min_samples_split = algoDict[modelStr]['min_samples_per_leaf_min_value']\n",
    "        )\n",
    "    elif modelStr == 'RandomForestRegressor':\n",
    "        return RandomForestRegressor(\n",
    "            n_estimators = algoDict[modelStr]['max_trees'],\n",
    "            max_depth = algoDict[modelStr]['max_depth'],\n",
    "            min_samples_split = algoDict[modelStr]['min_samples_per_leaf_min_value']\n",
    "        )\n",
    "    elif modelStr == 'GBTClassifier':\n",
    "        return GradientBoostingClassifier(\n",
    "            subsample = algoDict[modelStr]['min_subsample'],\n",
    "            max_depth = algoDict[modelStr]['max_depth'],\n",
    "            loss = lossGBT(algoDict, 'clf')\n",
    "        )\n",
    "    elif modelStr == 'GBTRegressor':\n",
    "        return GradientBoostingRegressor(\n",
    "            subsample = algoDict[modelStr]['min_subsample'],\n",
    "            max_depth = algoDict[modelStr]['max_depth'],\n",
    "            loss = lossGBT(algoDict, 'reg')\n",
    "        )\n",
    "    elif modelStr == 'LinearRegression':\n",
    "        return LinearRegression()\n",
    "    \n",
    "    elif modelStr == 'LogisticRegression':\n",
    "        return LogisticRegression(\n",
    "            max_iter = algoDict[modelStr]['max_iter'],\n",
    "            penalty='elasticnet',\n",
    "            l1_ratio=algoDict[modelStr]['max_elasticnet']\n",
    "        )\n",
    "    elif modelStr == 'RidgeRegression':\n",
    "        if type(algoDict[modelStr]['regularization_term']) in [int, float]:\n",
    "            return Ridge(\n",
    "                alpha = algoDict[modelStr]['regularization_term'],\n",
    "                max_iter = algoDict[modelStr]['max_iter']\n",
    "            )\n",
    "        else:\n",
    "            return Ridge(\n",
    "                max_iter = algoDict[modelStr]['max_iter']\n",
    "            )\n",
    "    elif modelStr == 'LassoRegression':\n",
    "        if type(algoDict[modelStr]['regularization_term']) in [int, float]:\n",
    "            return Lasso(\n",
    "                alpha = algoDict[modelStr]['regularization_term'],\n",
    "                max_iter = algoDict[modelStr]['max_iter']\n",
    "            )\n",
    "        else:\n",
    "            return Lasso(\n",
    "                max_iter = algoDict[modelStr]['max_iter']\n",
    "            )\n",
    "    elif modelStr == 'ElasticNetRegression':\n",
    "        if type(algoDict[modelStr]['regularization_term']) in [int, float]:\n",
    "            return ElasticNet(\n",
    "                alpha = algoDict[modelStr]['regularization_term'],\n",
    "                max_iter = algoDict[modelStr]['max_iter']\n",
    "            )\n",
    "        else:\n",
    "            return ElasticNet(\n",
    "                max_iter = algoDict[modelStr]['max_iter']\n",
    "            )\n",
    "    elif modelStr == 'xgboost':\n",
    "        if regtype == 'regression':\n",
    "            if algoDict[modelStr]['dart'] == True:\n",
    "                return XGBRegressor(\n",
    "                    max_depth = algoDict[modelStr]['max_depth_of_tree'][0],\n",
    "                    learning_rate = algoDict[modelStr]['learningRate'],\n",
    "                    booster = 'dart',\n",
    "                    gamma = algoDict[modelStr]['gamma'][0],\n",
    "                    min_child_weight = algoDict[modelStr]['min_child_weight'][0],\n",
    "                    reg_alpha = algoDict[modelStr]['l1_regularization'],\n",
    "                    reg_lambda = algoDict[modelStr]['l2_regularization'],\n",
    "                    random_state = algoDict[modelStr]['random_state'],\n",
    "                    early_stopping_rounds = algoDict[modelStr]['early_stopping_rounds']\n",
    "                    \n",
    "                )\n",
    "            else:\n",
    "                return XGBRegressor(\n",
    "                    max_depth = algoDict[modelStr]['max_depth_of_tree'][0],\n",
    "                    learning_rate = algoDict[modelStr]['learningRate'],\n",
    "                    gamma = algoDict[modelStr]['gamma'][0],\n",
    "                    min_child_weight = algoDict[modelStr]['min_child_weight'][0],\n",
    "                    reg_alpha = algoDict[modelStr]['l1_regularization'],\n",
    "                    reg_lambda = algoDict[modelStr]['l2_regularization'],\n",
    "                    random_state = algoDict[modelStr]['random_state'],\n",
    "                    early_stopping_rounds = algoDict[modelStr]['early_stopping_rounds']\n",
    "                    \n",
    "                )\n",
    "        elif regtype == 'classification':\n",
    "            if algoDict[modelStr]['dart'] == True:\n",
    "                return XGBClassifier(\n",
    "                    max_depth = algoDict[modelStr]['max_depth_of_tree'][0],\n",
    "                    learning_rate = algoDict[modelStr]['learningRate'],\n",
    "                    booster = 'dart',\n",
    "                    gamma = algoDict[modelStr]['gamma'][0],\n",
    "                    min_child_weight = algoDict[modelStr]['min_child_weight'][0],\n",
    "                    reg_alpha = algoDict[modelStr]['l1_regularization'],\n",
    "                    reg_lambda = algoDict[modelStr]['l2_regularization'],\n",
    "                    random_state = algoDict[modelStr]['random_state'],\n",
    "                    early_stopping_rounds = algoDict[modelStr]['early_stopping_rounds']\n",
    "                    \n",
    "                )\n",
    "            else:\n",
    "                return XGBClassifier(\n",
    "                    max_depth = algoDict[modelStr]['max_depth_of_tree'][0],\n",
    "                    learning_rate = algoDict[modelStr]['learningRate'],\n",
    "                    gamma = algoDict[modelStr]['gamma'][0],\n",
    "                    min_child_weight = algoDict[modelStr]['min_child_weight'][0],\n",
    "                    reg_alpha = algoDict[modelStr]['l1_regularization'],\n",
    "                    reg_lambda = algoDict[modelStr]['l2_regularization'],\n",
    "                    random_state = algoDict[modelStr]['random_state'],\n",
    "                    early_stopping_rounds = algoDict[modelStr]['early_stopping_rounds']\n",
    "                    \n",
    "                )\n",
    "    elif modelStr == 'DecisionTreeClassifier':\n",
    "        return DecisionTreeClassifier(\n",
    "            max_depth = algoDict[modelStr]['max_depth'],\n",
    "            min_samples_leaf= algoDict[modelStr]['min_samples_per_leaf'][0],\n",
    "            criterion = critDT(algoDict, 'clf'),\n",
    "            splitter = splitDT(algoDict, 'clf')\n",
    "        )\n",
    "    elif modelStr == 'DecisionTreeRegressor':\n",
    "        return DecisionTreeRegressor(\n",
    "            max_depth = algoDict[modelStr]['max_depth'],\n",
    "            min_samples_leaf= algoDict[modelStr]['min_samples_per_leaf'][0],\n",
    "            splitter = splitDT(algoDict, 'reg')\n",
    "        )\n",
    "    elif modelStr == 'SVM':\n",
    "        if regtype == 'regression':\n",
    "            return SVR(\n",
    "                kernel = kernelSVM(algoDict),\n",
    "                C = algoDict[modelStr]['c_value'][0],\n",
    "                tol = algoDict[modelStr]['tolerance'],\n",
    "                max_iter= algoDict[modelStr]['max_iterations'],\n",
    "                gamma = gammaSVM(algoDict)\n",
    "            )\n",
    "        elif regtype == 'classification':\n",
    "            return SVC(\n",
    "                kernel = kernelSVM(algoDict),\n",
    "                C = algoDict[modelStr]['c_value'][0],\n",
    "                tol = algoDict[modelStr]['tolerance'],\n",
    "                max_iter= algoDict[modelStr]['max_iterations'],\n",
    "                gamma = gammaSVM(algoDict)\n",
    "            )\n",
    "    elif modelStr == 'SGD':\n",
    "        return SGDClassifier(\n",
    "            tol = algoDict[modelStr]['tolerance'],\n",
    "            alpha = algoDict[modelStr]['alpha_value'][0],\n",
    "            loss = lossSGD(algoDict),\n",
    "            penalty = penaltySGD(algoDict)\n",
    "\n",
    "        )\n",
    "    elif modelStr == 'KNN':\n",
    "        if regtype == 'regression':\n",
    "            return KNeighborsRegressor(\n",
    "                n_neighbors = algoDict[modelStr]['k_value'][0],\n",
    "                p = algoDict[modelStr]['p_value'],\n",
    "                weights = weightKNN(algoDict)\n",
    "\n",
    "            )\n",
    "        elif regtype == 'classification':\n",
    "            return KNeighborsClassifier(\n",
    "                n_neighbors = algoDict[modelStr]['k_value'][0],\n",
    "                p = algoDict[modelStr]['p_value'],\n",
    "                weights = weightKNN(algoDict)\n",
    "            )\n",
    "    elif modelStr == 'extra_random_trees':\n",
    "        if regtype == 'regression':\n",
    "            return ExtraTreesRegressor(\n",
    "                n_estimators = algoDict[modelStr]['num_of_trees'][0],\n",
    "                max_depth = algoDict[modelStr]['max_depth'[0]],\n",
    "                min_samples_leaf = algoDict[modelStr]['min_sample_per_leaf'][0]\n",
    "            )\n",
    "        elif regtype == 'classification':\n",
    "            return ExtraTreesClassifier(\n",
    "                n_estimators = algoDict[modelStr]['num_of_trees'][0],\n",
    "                max_depth = algoDict[modelStr]['max_depth'[0]],\n",
    "                min_samples_leaf = algoDict[modelStr]['min_sample_per_leaf'][0]\n",
    "            )\n",
    "    elif modelStr == 'neural_netwrok':\n",
    "        if regtype == 'regression':\n",
    "            return MLPRegressor(\n",
    "                hidden_layer_sizes = algoDict[modelStr]['hidden_layer_sizes'],\n",
    "                alpha = algoDict[modelStr]['alpha_value'],\n",
    "                max_iter = algoDict[modelStr]['max_iterations'],\n",
    "                tol = algoDict[modelStr]['convergence_tolerance'],\n",
    "                early_stopping = algoDict[modelStr]['early_stopping'],\n",
    "                shuffle = algoDict[modelStr]['shuffle_data'],\n",
    "                learning_rate_init = algoDict[modelStr]['initial_learning_rate'],\n",
    "                beta_1 = algoDict[modelStr]['beta_1'],\n",
    "                beta_2 = algoDict[modelStr]['beta_2'],\n",
    "                epsilon = algoDict[modelStr]['epsilon'],\n",
    "                power_t = algoDict[modelStr]['power_t'],\n",
    "                momentum = algoDict[modelStr]['momentum'],\n",
    "            )\n",
    "        elif regtype == 'classification':\n",
    "            return MLPClassifier(\n",
    "                hidden_layer_sizes = algoDict[modelStr]['hidden_layer_sizes'],\n",
    "                alpha = algoDict[modelStr]['alpha_value'],\n",
    "                max_iter = algoDict[modelStr]['max_iterations'],\n",
    "                tol = algoDict[modelStr]['convergence_tolerance'],\n",
    "                early_stopping = algoDict[modelStr]['early_stopping'],\n",
    "                shuffle = algoDict[modelStr]['shuffle_data'],\n",
    "                learning_rate_init = algoDict[modelStr]['initial_learning_rate'],\n",
    "                beta_1 = algoDict[modelStr]['beta_1'],\n",
    "                beta_2 = algoDict[modelStr]['beta_2'],\n",
    "                epsilon = algoDict[modelStr]['epsilon'],\n",
    "                power_t = algoDict[modelStr]['power_t'],\n",
    "                momentum = algoDict[modelStr]['momentum'],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use getTarget() and transformStrToModelObj() to return model object list\n",
    "def getAlgorithm(algoDict, targetDict):\n",
    "    _, regtype = getTarget(targetDict)\n",
    "    if regtype.lower() == 'regression':\n",
    "        possibleModels = ['RandomForestRegressor', 'GBTRegressor', 'LinearRegression',\n",
    "                          'RidgeRegression', 'LassoRegression', 'ElasticNetRegression',\n",
    "                          'xg_boost', 'DecisionTreeRegressor', 'neural_network',\n",
    "                          'SVM', 'KNN', 'extra_random_trees']\n",
    "        selectedModels = []\n",
    "        for models in possibleModels:\n",
    "            if algoDict[models]['is_selected'] == True:\n",
    "                selectedModels.append(models)\n",
    "        modelsObjDict = {}\n",
    "        for models in selectedModels:\n",
    "            modelsObjDict[models] = transformStrToModelObj(models, algorithms, regtype)\n",
    "        return modelsObjDict\n",
    "        \n",
    "\n",
    "    elif regtype.lower() == 'classification':\n",
    "        possibleModels = ['RandomForestClassifier', 'GBTClassifier', 'LogisticRegression',\n",
    "                          'xg_boost', 'DecisionTreeClassifier', 'neural_network',\n",
    "                          'SVM', 'SGD', 'KNN', 'extra_random_trees']\n",
    "        selectedModels = []\n",
    "        for models in possibleModels:\n",
    "            if algoDict[models]['is_selected'] == True:\n",
    "                selectedModels.append(models)\n",
    "        for i in selectedModels:\n",
    "            modelsObjDict[i] = transformStrToModelObj(models, algorithms, regtype)\n",
    "        return modelsObjDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Handling\n",
    "def featureHandling(df):\n",
    "    for var, feature in feature_handling.items():\n",
    "        if feature['is_selected'] == False:\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "        if feature['feature_variable_type'] == 'numerical':\n",
    "            if feature['feature_details']['missing_values'] == 'Impute':\n",
    "                if feature['feature_details']['impute_with'] == 'Average of values':\n",
    "                    df[var].fillna(df[var].mean(), inplace=True)\n",
    "                elif feature['feature_details']['impute_with'] == 'custom':\n",
    "                    df[var].fillna(feature['feature_details']['impute_value'], inplace=True)\n",
    "        elif feature['feature_variable_type'] == 'text':\n",
    "            df[var] = LabelEncoder().fit_transform(df[var])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Reduction\n",
    "def featureReduction():\n",
    "    targetVar, regtype = getTarget(target)\n",
    "\n",
    "    X = df.drop(targetVar, axis=1).to_numpy()\n",
    "    y = df[targetVar].to_numpy()\n",
    "\n",
    "    if feature_reduction['feature_reduction_method'] == 'Tree-based':\n",
    "        if regtype == 'regression':\n",
    "            selector = SelectFromModel(\n",
    "                RandomForestRegressor(\n",
    "                n_estimators=int(feature_reduction['num_of_trees']),\n",
    "                max_depth=int(feature_reduction['depth_of_trees'])\n",
    "                )).fit(X, y)\n",
    "\n",
    "        elif regtype == 'classification':\n",
    "            selector = SelectFromModel(RandomForestClassifier(\n",
    "                n_estimators=int(feature_reduction['num_of_trees']),\n",
    "                max_depth=int(feature_reduction['depth_of_trees'])\n",
    "                )).fit(X, y)\n",
    "            \n",
    "        featImp = selector.estimator_.feature_importances_\n",
    "        featImp = [(j,i) for i,j in enumerate(featImp)]\n",
    "        featImp.sort(reverse=True)\n",
    "        featImpIndex = [y for _, y in featImp[:eval(feature_reduction['num_of_features_to_keep'])]]\n",
    "        \n",
    "        tempdf = df.iloc[:,featImpIndex]\n",
    "        return tempdf.to_numpy()\n",
    "\n",
    "    elif feature_reduction['feature_reduction_method'] == 'Principal Component Analysis':\n",
    "        pca = PCA(n_components=int(feature_reduction['num_of_features_to_keep'])).fit(X)\n",
    "        X = pca.transform(X)\n",
    "        return X\n",
    "\n",
    "    elif feature_reduction['feature_reduction_method'] == 'Correlation with target':\n",
    "        corr = df.corr()[targetVar].drop(targetVar)\n",
    "        corr = [(j,i) for i,j in zip(corr.index, corr.values)]\n",
    "        corr.sort(reverse=True)\n",
    "        corrIndex = [y for _, y in corr[:eval(feature_reduction['num_of_features_to_keep'])]]\n",
    "        \n",
    "        tempdf = df.loc[:,corrIndex]\n",
    "        return tempdf.to_numpy()\n",
    "\n",
    "    elif feature_reduction['feature_reduction_method'] == 'No Reduction':\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestRegressor': RandomForestRegressor(max_depth=25, min_samples_split=5, n_estimators=20),\n",
       " 'GBTRegressor': GradientBoostingRegressor(loss='exponential', max_depth=7, subsample=1)}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAlgorithm(algorithms, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = session_info['dataset']\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = featureHandling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = featureReduction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
